{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11797813,"sourceType":"datasetVersion","datasetId":7408624}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPt+/7KwOWko/9wU0LdJ48G"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom datasets import Dataset\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\nfrom trl import SFTTrainer\nfrom transformers import EarlyStoppingCallback","metadata":{"id":"zY0Klne4XBIX","executionInfo":{"status":"ok","timestamp":1746788000586,"user_tz":-180,"elapsed":19217,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:49:15.998111Z","iopub.execute_input":"2025-05-13T17:49:15.998812Z","iopub.status.idle":"2025-05-13T17:49:24.795606Z","shell.execute_reply.started":"2025-05-13T17:49:15.998785Z","shell.execute_reply":"2025-05-13T17:49:24.795038Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"2025-05-13 17:49:22.030802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747158562.053174     303 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747158562.060293     303 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install trl==0.11.0\n! pip install -U bitsandbytes","metadata":{"id":"V531RX7F156n","executionInfo":{"status":"ok","timestamp":1746787830741,"user_tz":-180,"elapsed":130056,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"outputId":"41054586-66f1-426a-b677-6502be5fbc37","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## upload dataset","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/bilingual-construction-dataset/bilingual_construction_dataset_translated.json', 'r') as file:\n    data = json.load(file)\n","metadata":{"id":"eiNuy0ZhY96-","executionInfo":{"status":"ok","timestamp":1746779380905,"user_tz":-180,"elapsed":117,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:50:36.408677Z","iopub.execute_input":"2025-05-13T17:50:36.409414Z","iopub.status.idle":"2025-05-13T17:50:36.489644Z","shell.execute_reply.started":"2025-05-13T17:50:36.409387Z","shell.execute_reply":"2025-05-13T17:50:36.489102Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### format the json file","metadata":{}},{"cell_type":"code","source":"formatted_bilingual = [\n    {\"text\": f\"### Human: {row['instruction_en']}\\n### Assistant: {row['response_en']}\"} \n    for row in data\n] + [\n    {\"text\": f\"### Human: {row['instruction_ar']}\\n### Assistant: {row['response_ar']}\"} \n    for row in data\n]\n\ndataset = Dataset.from_pandas(pd.DataFrame(formatted_bilingual))\ndataset = dataset.train_test_split(test_size=0.1)","metadata":{"id":"DSQjNcyZncw2","executionInfo":{"status":"ok","timestamp":1746779384622,"user_tz":-180,"elapsed":815,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:50:46.417110Z","iopub.execute_input":"2025-05-13T17:50:46.417396Z","iopub.status.idle":"2025-05-13T17:50:46.497344Z","shell.execute_reply.started":"2025-05-13T17:50:46.417375Z","shell.execute_reply":"2025-05-13T17:50:46.496585Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T22:17:50.645860Z","iopub.execute_input":"2025-05-13T22:17:50.646217Z","iopub.status.idle":"2025-05-13T22:17:50.662565Z","shell.execute_reply.started":"2025-05-13T22:17:50.646193Z","shell.execute_reply":"2025-05-13T22:17:50.661752Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3200aa0d17894d968ee4ac293da6f7b5"}},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"## upload the tokenizer and the model","metadata":{}},{"cell_type":"code","source":"# --- Tokenizer ---\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"id":"1fkxgUKlnrFN","executionInfo":{"status":"ok","timestamp":1746779389993,"user_tz":-180,"elapsed":365,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:50:57.122561Z","iopub.execute_input":"2025-05-13T17:50:57.122834Z","iopub.status.idle":"2025-05-13T17:50:57.397391Z","shell.execute_reply.started":"2025-05-13T17:50:57.122814Z","shell.execute_reply":"2025-05-13T17:50:57.396620Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n# Quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=\"float16\"\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"meta-llama/Llama-2-7b-hf\",\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)","metadata":{"id":"qtiM_8vDo_-a","executionInfo":{"status":"error","timestamp":1746788093111,"user_tz":-180,"elapsed":988,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"outputId":"c72f7202-bb32-47e3-f92e-29dc3655e1bc","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:51:04.929745Z","iopub.execute_input":"2025-05-13T17:51:04.930480Z","iopub.status.idle":"2025-05-13T17:51:25.849381Z","shell.execute_reply.started":"2025-05-13T17:51:04.930452Z","shell.execute_reply":"2025-05-13T17:51:25.848708Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a334b1d502db4d68af12f5d44c81a097"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"pip install -U bitsandbytes","metadata":{"id":"PZTFUVEAHCw6","executionInfo":{"status":"ok","timestamp":1746778568636,"user_tz":-180,"elapsed":97294,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"outputId":"b6b51508-8855-42be-8eea-98aa2f58e849","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### use lora configration","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\nmodel = prepare_model_for_kbit_training(model)\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"id":"-w1gzIUerDse","executionInfo":{"status":"ok","timestamp":1746779396816,"user_tz":-180,"elapsed":73,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:51:33.307279Z","iopub.execute_input":"2025-05-13T17:51:33.307892Z","iopub.status.idle":"2025-05-13T17:51:33.327860Z","shell.execute_reply.started":"2025-05-13T17:51:33.307866Z","shell.execute_reply":"2025-05-13T17:51:33.327343Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"id":"ApYHgADUrKWW","executionInfo":{"status":"ok","timestamp":1746779404531,"user_tz":-180,"elapsed":268,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"outputId":"df1af85c-f426-42ff-f2a0-b481975ee678","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:51:39.433532Z","iopub.execute_input":"2025-05-13T17:51:39.434197Z","iopub.status.idle":"2025-05-13T17:51:39.670384Z","shell.execute_reply.started":"2025-05-13T17:51:39.434168Z","shell.execute_reply":"2025-05-13T17:51:39.669783Z"}},"outputs":[{"name":"stdout","text":"trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### setting training parameters","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n\nfrom transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./llama2-7b-egyptian-construction-lora\",\n    per_device_train_batch_size=1,      # Lowered\n    per_device_eval_batch_size=1,       # Lowered\n    gradient_accumulation_steps=2,      # Or 1 if still OOM\n    max_steps=1000,                      # For quick test\n    learning_rate=2e-4,\n    fp16=True,\n    logging_steps=50,\n    save_steps=100,\n    eval_strategy=\"steps\",\n    eval_steps=100,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    report_to=\"wandb\",\n    run_name=\"egyptian-construction-chatbot-v1\",\n)","metadata":{"id":"nTsH47odIkb0","executionInfo":{"status":"ok","timestamp":1746779406878,"user_tz":-180,"elapsed":57,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:51:48.151374Z","iopub.execute_input":"2025-05-13T17:51:48.152090Z","iopub.status.idle":"2025-05-13T17:51:48.179643Z","shell.execute_reply.started":"2025-05-13T17:51:48.152047Z","shell.execute_reply":"2025-05-13T17:51:48.179106Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(dataset[\"train\"][0])\nprint(dataset[\"train\"].features)","metadata":{"id":"A6Yyds_4xRHE","executionInfo":{"status":"ok","timestamp":1746728494553,"user_tz":-180,"elapsed":17,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"outputId":"cb1905eb-6cb7-4ac9-cb5d-4b32198aea84","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install wandb --quiet\n!wandb login 771825ea45b66d37e930eaecd1a00b8fe61ccfed\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### intialiaze wnadb project to track the training","metadata":{}},{"cell_type":"code","source":"import wandb\nwandb.init(\n    project=\"egyptian-construction-chatbot-v1\",\n    name=\"debug-run\",\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Trainer setup\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    args=training_args,\n    tokenizer=tokenizer,\n    peft_config=lora_config,\n    dataset_text_field=\"text\",\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=20)],\n)","metadata":{"id":"pyqnuBMLJVNk","executionInfo":{"status":"error","timestamp":1746787890487,"user_tz":-180,"elapsed":370,"user":{"displayName":"Ahmed Hussein","userId":"02317312714693905782"}},"outputId":"4ff9619b-d0f1-455e-f4cf-b23994e28054","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:52:03.641358Z","iopub.execute_input":"2025-05-13T17:52:03.641883Z","iopub.status.idle":"2025-05-13T17:52:06.684042Z","shell.execute_reply.started":"2025-05-13T17:52:03.641861Z","shell.execute_reply":"2025-05-13T17:52:06.683326Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10404 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6ab640898894b9bb45fb96f7e3b7d3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1156 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4da55099baf4b6596340d02c2aebc20"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  super().__init__(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"trainer.train()\nmodel.save_pretrained(\"./lora\")\ntokenizer.save_pretrained(\"./lora\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:52:13.081681Z","iopub.execute_input":"2025-05-13T17:52:13.082421Z","iopub.status.idle":"2025-05-13T21:11:25.577181Z","shell.execute_reply.started":"2025-05-13T17:52:13.082398Z","shell.execute_reply":"2025-05-13T21:11:25.576411Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mahmeddewdar45\u001b[0m (\u001b[33mahmeddewdar45-alexandria-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250513_175219-9ap66gkp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ahmeddewdar45-alexandria-university/huggingface/runs/9ap66gkp' target=\"_blank\">egyptian-construction-chatbot-v1</a></strong> to <a href='https://wandb.ai/ahmeddewdar45-alexandria-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ahmeddewdar45-alexandria-university/huggingface' target=\"_blank\">https://wandb.ai/ahmeddewdar45-alexandria-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ahmeddewdar45-alexandria-university/huggingface/runs/9ap66gkp' target=\"_blank\">https://wandb.ai/ahmeddewdar45-alexandria-university/huggingface/runs/9ap66gkp</a>"},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 3:18:54, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.442200</td>\n      <td>1.478307</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.370300</td>\n      <td>1.391276</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.310100</td>\n      <td>1.350127</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.279100</td>\n      <td>1.310227</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.173300</td>\n      <td>1.285482</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.205200</td>\n      <td>1.261849</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.194900</td>\n      <td>1.246149</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.159200</td>\n      <td>1.230777</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.199000</td>\n      <td>1.222252</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.145300</td>\n      <td>1.217482</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('./lora/tokenizer_config.json',\n './lora/special_tokens_map.json',\n './lora/tokenizer.model',\n './lora/added_tokens.json',\n './lora/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"  print(len(dataset[\"train\"]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### load the model to hugging face repositery","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\napi.upload_folder(\n    folder_path=\"./lora\",\n    repo_id=\"AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter\",\n    repo_type=\"model\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T22:18:50.634404Z","iopub.execute_input":"2025-05-13T22:18:50.635244Z","iopub.status.idle":"2025-05-13T22:18:55.191807Z","shell.execute_reply.started":"2025-05-13T22:18:50.635218Z","shell.execute_reply":"2025-05-13T22:18:55.191250Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9b476a49ea34fa686c686a18bc65057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"015393797b784f7ab3dc0346769278b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/33.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"640f23555f0a4c758af51ea80420bc62"}},"metadata":{}},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter/commit/29a71d13a7029314a7e1dc24a03566ef585b82a4', commit_message='Upload folder using huggingface_hub', commit_description='', oid='29a71d13a7029314a7e1dc24a03566ef585b82a4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\napi.create_repo(\"AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter\", private=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T22:18:07.013187Z","iopub.execute_input":"2025-05-13T22:18:07.013469Z","iopub.status.idle":"2025-05-13T22:18:14.477830Z","shell.execute_reply.started":"2025-05-13T22:18:07.013450Z","shell.execute_reply":"2025-05-13T22:18:14.477267Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='AhmedHussein66/llama2-7b-egyptian-construction-lora-lora-adapter')"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"### evaluate the model ","metadata":{}},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(\"Evaluation results:\", eval_results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T22:21:41.252633Z","iopub.execute_input":"2025-05-13T22:21:41.253347Z","iopub.status.idle":"2025-05-13T22:34:56.035102Z","shell.execute_reply.started":"2025-05-13T22:21:41.253324Z","shell.execute_reply":"2025-05-13T22:34:56.034480Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1156' max='1156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1156/1156 13:13]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 1.2174819707870483, 'eval_runtime': 794.7723, 'eval_samples_per_second': 1.455, 'eval_steps_per_second': 1.455, 'epoch': 0.1922337562475971}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"### test the model","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator_ar_to_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ar-en\")\ntranslator_en_to_ar = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-ar\")\n\nchatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\ndef translate_and_chat(input_text):\n    input_en = translator_ar_to_en(input_text)[0]['translation_text']\n    \n    prompt = f\"### Human: {input_en}\\n### Assistant:\"\n    response = chatbot(prompt, max_new_tokens=100, temperature=0.7, top_p=0.9, repetition_penalty=1.2)\n    \n    assistant_response_en = response[0]['generated_text'].split(\"### Assistant:\")[-1].strip()\n    \n    assistant_response_ar = translator_en_to_ar(assistant_response_en)[0]['translation_text']\n    \n    return assistant_response_ar\n\narabic_question = \" ما الفرق بين ترخيص البناء وتصريح التشغيل\"\nanswer = translate_and_chat(arabic_question)\nprint(\"🧠 Assistant says in Arabic:\", answer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T22:41:00.485042Z","iopub.execute_input":"2025-05-13T22:41:00.485831Z","iopub.status.idle":"2025-05-13T22:41:10.505722Z","shell.execute_reply.started":"2025-05-13T22:41:00.485803Z","shell.execute_reply":"2025-05-13T22:41:10.504946Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\nDevice set to use cuda:0\nThe model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n","output_type":"stream"},{"name":"stdout","text":"🧠 Assistant says in Arabic: ترخيص البناء يسمح بالبناء، في حين يسمح ترخيص التشغيل (مثلاً للمصنع) للشركات بالعمل بشكل قانوني في مواقع معينة بعد الإنجاز. غالباً ما تطلب من قبل سلطات مثل EMA أو MOPH. بدون ترخيص تشغيلي، لا يمكنك فتح أبوابك! لذا احصل على كلاهما إذا لزم الأمر قبل الشروع في أي مشروع جديد؛ وإلا فإنك تخاطر بدفع غرامات أو أوامر إغلاق بسبب انتهاك قوانين المدينة بدونها.\n","output_type":"stream"}],"execution_count":46}]}